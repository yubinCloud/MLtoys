# MLtoys

Machine learning toys that help me learn.

## Description

### [deep-thoughts](./deep-thoughts/)

The code of bilibili up owner [deep-thoughts](https://space.bilibili.com/373596439) in action.

| Loc   | Description | Tags |
| :---: | :---       | :---  |
|[Transformer 难点逐行实现](./deep-thoughts/Transformer%20%E9%9A%BE%E7%82%B9%E7%90%86%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0.ipynb) | 使用 PyTorch 逐行实现了 Transformer 中关键的 Self-Attention、Position Embedding、三种不同的 mask 和 mask loss | Transformer, Self-Attention, Masked Self-Attention |
| [RNN 复现](./deep-thoughts/RNN%20%E5%A4%8D%E7%8E%B0.ipynb) | 使用 PyTorch 逐行实现了 RNN、双向 RNN、LSTM、LSTMP、GRU，并与官方实现的运算结果进行了对比，结果一致 | RNN, BiRNN, LSTM, LSTMP, GRU |
| [Attention-based Seq2Seq](./deep-thoughts/Attention-based%20seq2seq%20%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9E%E7%8E%B0%E7%A4%BA%E4%BE%8B.ipynb) | 实现了一个 Attention-based 的 Seq2Seq 模型 | seq2seq, attention, LSTM |

### [LHY-HW](./LHY-HW/)

Homework for Hongyi Lee's course

| Loc   | Description | Tags |
| :---: | :---       | :---  |
|[HW4-2021-speaker-classification](./LHY-HW/HW5-2021-Seq2Seq.ipynb) | Classify the speakers of given features. | Transformer, speech processing |
|[HW5-2021-Seq2Seq](./LHY-HW/HW5-2021-Seq2Seq.ipynb) | Using the seq2seq architecture for machine translation tasks. | NMT, RNN, Attention, Transformer, seq2seq |

### [tutorials/huggingface](./tutorials/huggingface-tutorials/)

 A tutorials of how to use *HuggingFace*.

#### [蓝斯诺特](./tutorials/huggingface-tutorials/%E8%93%9D%E6%96%AF%E8%AF%BA%E7%89%B9/)

 B 站 up 主 [蓝斯诺特](https://space.bilibili.com/7877324) 的 HuggingFace 教程

 | Loc   | Description | Tags |
| :---: | :---       | :---  |
| [01.install](./tutorials/huggingface-tutorials/%E8%93%9D%E6%96%AF%E8%AF%BA%E7%89%B9/01.install.ipynb) | HuggingFace 的安装 | HuggingFace, PyTorch |
| [02.tokenizer](./tutorials/huggingface-tutorials/%E8%93%9D%E6%96%AF%E8%AF%BA%E7%89%B9/02.tokenizer.ipynb) | Tokenizer 的使用 | HuggingFace, Tokenizer, BERT |
| [03.datasets](./tutorials/huggingface-tutorials/%E8%93%9D%E6%96%AF%E8%AF%BA%E7%89%B9/03.datasets.ipynb) | HuggingFace 中 datasets 的使用 | HuggingFace, Dataset |
| [04.metrics](./tutorials/huggingface-tutorials/%E8%93%9D%E6%96%AF%E8%AF%BA%E7%89%B9/04.metrics.ipynb) | HuggingFace 中评价函数的使用的示例 | HuggingFace, metrics |
| [05.pipeline](./tutorials/huggingface-tutorials/%E8%93%9D%E6%96%AF%E8%AF%BA%E7%89%B9/05.pipeline.ipynb) | HuggingFace 中 pipeline 的使用的示例 | HuggingFace, pipeline |
| [06.中文文本情感分类](./tutorials/huggingface-tutorials/%E8%93%9D%E6%96%AF%E8%AF%BA%E7%89%B9/06.%E4%B8%AD%E6%96%87%E5%88%86%E7%B1%BB.ipynb) | 使用 HuggingFace 中的 BERT 来做情感分类的任务，通过只对最后的 FC 层进行 fine-tuning 来进行训练并测试 | HuggingFace, BERT, sentiment-analysis |

